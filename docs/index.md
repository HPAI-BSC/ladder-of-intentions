---
title: ""
feature_image: "https://picsum.photos/1300/400?image=989"
feature_text: |
  ## Ladder of Intentions: unifying agent architectures for explainability and transferability
  Victor Gimenez-Abalos<sup>*,1</sup>, Adrian Tormos<sup>1</sup>, Filip Edström<sup>2</sup>, Sergio Alvarez-Napagao<sup>3,1</sup>, Javier Vázquez-Salceda<sup>3</sup>, Mattias Brännström<sup>2</sup>, John Lindqvist<sup>4</sup>
  <small>
    <br>
    <sup>*</sup>Corresponding author <victor.gimenez@bsc.es>
    <br>
    <sup>1</sup>Barcelona Supercomputing Center
    <br>
    <sup>2</sup>Umeå University
    <br>
    <sup>3</sup>Universitat Politècnica de Catalunya
    <br>
    <sup>4</sup>Universitetet i Bergen
  </small>
---


{% include button.html text="Paper" link="" color="#4f2121"  %} {% include button.html text="BlueSky" link="https://bsky.app/profile/hpai.bsky.social" color="rgb(32, 139, 254)" %}  {% include button.html text="Linkedin" link="https://www.linkedin.com/company/hpai" color="#0a66c2" %}

### Abstract

> Within the field of Autonomous Agents, the predominant paradigm is that agents perceive, reflect, reason, and act on an environment, employing some specific decision mechanism to pick actions. 
Nonetheless, the process that originates the decisions may differ depending on the agent, as this paradigm is agnostic about its concrete action selection inference.
However, the need for being able to explain these decisions is constantly increasing, and the heterogeneity of the internal processes of agents has ended up in different ad hoc techniques for each architecture, for providing explanations with disparate validation mechanisms, hindering efforts at comparing mechanisms.
>
> To tackle this, in this contribution, we propose a unifying architecture framework based on causality, beliefs, and intentions. This framework allows for the examination of heterogeneous agents (from BDI and RL to LLM-based agents) without modification. 
This approach clearly decouples declarative and procedural knowledge, as well as designer-given versus learnt representations. 
It categorises what kind of questions can be answered by each agent reasoning component and allows a more seamless workflow for transferring knowledge between diverse agent architectures.

### Cite as

```
@inproceedings{gimenez_ladder_2025,
author = {Gimenez-Abalos, Victor and Tormos, Adrian and Edström, Filip and Alvarez-Napagao, Sergio and Vázquez-Salceda, Javier and Brännström, Mattias and Lindqvist, John},
title = {Ladder of Intentions: unifying agent architectures for explainability and transferability},
year = {2025},
TODO: EXTRAAMAS block
}
```